import streamlit as st
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import firebase_admin
from firebase_admin import credentials, firestore
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import KMeans
from sklearn.metrics import pairwise_distances_argmin_min

st.set_page_config(page_title="Music Fusion Recommender", layout="wide")

import json
AUDIO_DIR = "song"

# FirebaseåˆæœŸåŒ–
if not firebase_admin._apps:
    try:
        # â˜…ã“ã“ãŒä¿®æ­£ãƒã‚¤ãƒ³ãƒˆï¼
        # KEY_PATH ã§ã¯ãªãã€st.secrets ã‹ã‚‰ç›´æ¥èª­ã¿è¾¼ã¿ã¾ã™
        key_dict = json.loads(st.secrets["FIREBASE_KEY"])
        cred = credentials.Certificate(key_dict)
        firebase_admin.initialize_app(cred)
    except Exception as e:
        st.error(f"Firebaseæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()

db = firestore.client()

# ==========================================
# 2. ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰
# ==========================================
@st.cache_data
def load_data_from_firebase():
    docs = db.collection('songs').stream()
    features_list = []
    filenames_list = []
    
    for doc in docs:
        data = doc.to_dict()
        vec = data['features']
        if 'tempo' in data:
            vec.append(data['tempo'])
        features_list.append(vec)
        filenames_list.append(data['filename'])
        
    if not features_list: return None, None
    return np.array(features_list), np.array(filenames_list)

with st.spinner('Firebaseã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...'):
    X, filenames = load_data_from_firebase()

if X is None:
    st.error("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

# ==========================================
# 3. ä»£è¡¨æ›²ã®ç‰¹å®š (6æ›²)
# ==========================================
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
kmeans = KMeans(n_clusters=6, random_state=42)
labels = kmeans.fit_predict(X_scaled)
closest, _ = pairwise_distances_argmin_min(kmeans.cluster_centers_, X_scaled)

# ==========================================
# 4. ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆé–¢æ•°
# ==========================================
def plot_radar(vec1, vec2=None, label1="Mix Base", label2="Recommendation"):
    def get_metrics(vec):
        # [0-12]:Timbre, [13-25]:Var, [26-49]:Chroma, [50-63]:Energy, [64]:Tempo
        tempo = vec[64]
        energy = np.mean(vec[50:57])
        timbre = np.mean(vec[0:13])
        variation = np.mean(vec[13:26])
        return [tempo, energy, timbre, variation]

    # å…¨ä½“ã‚¹ã‚±ãƒ¼ãƒ«ç”¨
    all_metrics = np.array([get_metrics(x) for x in X])
    scaler_radar = MinMaxScaler()
    scaler_radar.fit(all_metrics)

    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    metrics1 = scaler_radar.transform([get_metrics(vec1)])[0].tolist()
    metrics1 += metrics1[:1]
    
    labels = ['Tempo', 'Energy', 'Timbre', 'Variation']
    angles = np.linspace(0, 2 * np.pi, len(labels), endpoint=False).tolist()
    angles += angles[:1]

    fig, ax = plt.subplots(figsize=(4, 4), subplot_kw=dict(polar=True))
    
    # ãƒ™ãƒ¼ã‚¹ï¼ˆ2æ›²ã®ãƒŸãƒƒã‚¯ã‚¹ï¼‰
    ax.plot(angles, metrics1, color='#007AFF', linewidth=2, label=label1)
    ax.fill(angles, metrics1, color='#007AFF', alpha=0.2)

    # æ¨è–¦æ›²
    if vec2 is not None:
        metrics2 = scaler_radar.transform([get_metrics(vec2)])[0].tolist()
        metrics2 += metrics2[:1]
        ax.plot(angles, metrics2, color='#FF3B30', linewidth=2, linestyle='--', label=label2)

    ax.set_yticklabels([])
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(labels, size=10)
    plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))
    return fig

# ==========================================
# 5. ã‚¢ãƒ—ãƒªç”»é¢ UI
# ==========================================
st.title("ğŸ›ï¸ Music Fusion Recommender")
st.markdown("ç•°ãªã‚‹2ã¤ã®æ›²ã‚’é¸æŠã—ã¦ã€ãã®ã€Œä¸­é–“ã€ã«ã‚ã‚‹æ›²ã‚’æ¢ã—ã¾ã™ã€‚")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼: 2æ›²é¸æŠ ---
st.sidebar.header("1. Select 2 Songs")
st.sidebar.write("ãƒŸãƒƒã‚¯ã‚¹ã—ãŸã„æ›²èª¿ã‚’2ã¤é¸ã‚“ã§ãã ã•ã„")

# é¸æŠè‚¢ã®ä½œæˆ
options = {f"Group {i+1} ({filenames[closest[i]]})": closest[i] for i in range(6)}
selected_labels = st.sidebar.multiselect(
    "ä»£è¡¨æ›²ãƒªã‚¹ãƒˆ:",
    options.keys(),
    max_selections=2
)

# --- 2æ›²é¸ã°ã‚Œã¦ã„ãªã„å ´åˆã®å‡¦ç† ---
if len(selected_labels) < 2:
    st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€æ··ãœåˆã‚ã›ãŸã„æ›²ã‚’ **2ã¤** é¸ã‚“ã§ãã ã•ã„ã€‚")
    
    # å‚è€ƒç”¨ã«å…¨ä»£è¡¨æ›²ã‚’è¡¨ç¤º
    st.subheader("ä»£è¡¨æ›²ãƒªã‚¹ãƒˆ (ã“ã“ã‹ã‚‰2ã¤é¸ã¹ã¾ã™)")
    cols = st.columns(3)
    for i in range(6):
        with cols[i%3]:
            idx = closest[i]
            st.write(f"**Group {i+1}**")
            audio_path = os.path.join(AUDIO_DIR, filenames[idx])
            if os.path.exists(audio_path):
                st.audio(audio_path)
            else:
                st.write(filenames[idx])
    st.stop()

# --- 2æ›²é¸ã°ã‚ŒãŸã‚ã¨ã®å‡¦ç† ---
idx1 = options[selected_labels[0]]
idx2 = options[selected_labels[1]]

# ãƒ™ã‚¯ãƒˆãƒ«åˆæˆ (å¹³å‡ã‚’å–ã‚‹)
mixed_vector = (X[idx1] + X[idx2]) / 2

st.sidebar.success(f"Mix created from:\n- {filenames[idx1]}\n- {filenames[idx2]}")

# --- ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ ---
col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("ğŸšï¸ å¾®èª¿æ•´ (Steering)")
    st.write("2æ›²ã®ä¸­é–“åœ°ç‚¹ã‹ã‚‰ã€ã•ã‚‰ã«å¥½ã¿ã‚’èª¿æ•´ã—ã¾ã™ã€‚")
    
    delta_tempo = st.slider("Tempo (é€Ÿã•)", -3.0, 3.0, 0.0)
    delta_energy = st.slider("Energy (æ¿€ã—ã•)", -3.0, 3.0, 0.0)
    delta_timbre = st.slider("Timbre (éŸ³ã®åšã¿)", -3.0, 3.0, 0.0)

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼èª¿æ•´ã‚’åŠ ãˆã‚‹
    final_target_vector = mixed_vector.copy()
    
    # çµ±è¨ˆé‡ã‚’ä½¿ã£ã¦èª¿æ•´å¹…ã‚’æ±ºã‚ã‚‹
    final_target_vector[64] += delta_tempo * np.std(X[:, 64]) * 0.5     # Tempo
    final_target_vector[50:57] += delta_energy * np.std(X[:, 50:57]) * 0.2 # Energy
    final_target_vector[0:13] += delta_timbre * np.std(X[:, 0:13]) * 0.2   # Timbre

    # æ¤œç´¢å®Ÿè¡Œ
    sim_scores = cosine_similarity([final_target_vector], X)[0]
    sorted_indices = sim_scores.argsort()[::-1]
    
    # è‡ªåˆ†è‡ªèº«ï¼ˆé¸ã‚“ã 2æ›²ï¼‰ãŒ1ä½ã«å‡ºã¦ãã‚‹ã®ã‚’é˜²ã
    recommendations = []
    for idx in sorted_indices:
        if idx != idx1 and idx != idx2: # é¸ã‚“ã æ›²ä»¥å¤–
            recommendations.append(idx)
        if len(recommendations) >= 3: # ãƒˆãƒƒãƒ—3ã¾ã§å–å¾—
            break
            
    top_rec_idx = recommendations[0]

with col2:
    st.subheader(" æ¨è–¦çµæœ (Fusion Result)")
    
    st.success(f"**Best Match:** {filenames[top_rec_idx]}")
    
    # å†ç”Ÿ
    rec_path = os.path.join(AUDIO_DIR, filenames[top_rec_idx])
    if os.path.exists(rec_path):
        st.audio(rec_path)
    else:
        st.warning("File not found")

    # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã§æ¯”è¼ƒ
    # é’è‰²: é¸ã‚“ã 2æ›²ã®ãƒŸãƒƒã‚¯ã‚¹ + ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼èª¿æ•´
    # èµ¤è‰²: å®Ÿéš›ã«æ¨è–¦ã•ã‚ŒãŸæ›²
    st.pyplot(plot_radar(final_target_vector, X[top_rec_idx], 
                         label1="Your Mix Target", label2="Recommended Song"))

st.markdown("---")
st.write("###ãã®ä»–ã®å€™è£œ (Top 2 & 3)")
sub_cols = st.columns(2)
for i, idx in enumerate(recommendations[1:3]):
    with sub_cols[i]:
        st.write(f"**{i+2}. {filenames[idx]}**")
        path = os.path.join(AUDIO_DIR, filenames[idx])
        if os.path.exists(path):
            st.audio(path)
